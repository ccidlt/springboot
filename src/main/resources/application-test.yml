server:
  port: 8078
  servlet:
    context-path: /
  # 开启Gzip压缩，默认只压缩超过2048字节的数据
  compression:
    enabled: true
    mime-types: application/json
spring:
  application:
    name: springboot
  jackson:
    date-format: yyyy-MM-dd HH:mm:ss
    time-zone: GMT+8
  datasource:
    #    driver-class-name: com.mysql.cj.jdbc.Driver
    #    url: jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=GMT%2B8
    #    username: root
    #    password: 123456
    dynamic:
      primary: master #设置默认的数据源或者数据源组,默认值即为master
      datasource:
        master:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=GMT%2B8
          username: root
          password: 123456
        slave:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=GMT%2B8
          username: root
          password: 123456
  cache:
    type: redis
  redis:
    #Redis服务器连接地址和端口
    host: 127.0.0.1
    port: 6379
    #Redis服务器连接密码（默认为空）
    password:
    jedis:
      pool:
        #连接池最大连接数（使用负值表示没有限制）
        max-active: 8
        #连接池最大阻塞等待时间（使用负值表示没有限制）
        max-wait: -1
        #连接池中的最大空闲连接
        max-idle: 8
        #连接池中的最小空闲连接
        min-idle: 0
    #    lettuce:
    #      pool:
    #        max-active: 8
    #        max-wait: -1
    #        max-idle: 8
    #        min-idle: 0
    #连接超时时间（毫秒）
    timeout: 30000
  session:
    store-type: redis #是否将session存到redis  none/redis
    timeout: 1000 # 配置session在redis中的过期时间
  servlet:
    multipart:
      max-file-size: 1024MB

  kafka:
    bootstrap-servers: 127.0.0.1:9092
    #producer生产者配置序列化
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      batch-size: 16384 #生产者每个批次最多放多少条记录
      buffer-memory: 33554432 #生产者一端总的可用发送缓存区大小，此处设置为32M
    #consumer消费者配置序列化
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      group-id: defaultGroupId
      auto-offset-reset: earliest #如果在kafka中找不到当前消费者的偏移量，则直接将偏移量重置为最早的
      #enable-auto-commit: true #消费者的偏移量是自动提交还是手动提交，此处自动提交偏移量
      #auto-commit-interval: 1000 #消费者偏移量自动提交的时间间隔
      enable-auto-commit: false #手动提交偏移量
      max-poll-records: 1000 #最大消费100条
    listener:
      type: batch #开启批量消费
      concurrency: 1 #同时处理线程数
      poll-timeout: 1500 #只限自动提交
      missing-topics-fatal: false #无主题不报异常
      ack-mode: manual #当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交

  quartz:
    #相关属性配置
    properties:
      org:
        quartz:
          scheduler:
            instanceName: clusteredScheduler
            instanceId: AUTO
          jobStore:
            class: org.quartz.impl.jdbcjobstore.JobStoreTX
            driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate
            tablePrefix: QRTZ_
            isClustered: true
            clusterCheckinInterval: 10000
            useProperties: false
          threadPool:
            class: org.quartz.simpl.SimpleThreadPool
            threadCount: 10
            threadPriority: 5
            threadsInheritContextClassLoaderOfInitializingThread: true
    #数据库方式jdbc/内存memory
    job-store-type: jdbc

#  rabbitmq:
#    host: 127.0.0.1
#    port: 5672
#    username: guest
#    password: guest


#logging:
#  level:
#    root: INFO
#    com.ds: DEBUG
#  file:
#    path: log
#  pattern:
#    console: "%d{yyyy/MM/dd-HH:mm:ss} [%thread] %-5level %logger- %msg%n"

#自动建表设置
mybatis:
  table:
    auto: update
    #create	    系统启动后，会将所有的表删除掉，然后根据model中配置的结构重新建表，该操作会破坏原有数据。
    #update	    系统会自动判断哪些表是新建的，哪些字段要修改类型等，哪些字段要删除，哪些字段要新增，该操作不会破坏原有数据。
    #none 		系统不做任何处理。
    #add		新增表/新增字段/新增索引/新增唯一约束的功能，不做做修改和删除 (只在版本1.0.9.RELEASE及以上支持)。
  model:
    pack: com.ds.entity.table #扫描用于创建表的对象的包名，多个包用“,”隔开
  database:
    type: mysql #数据库类型 目前只支持mysql

mybatis-plus:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.ds.entity
  configuration:
    map-underscore-to-camel-case: true #t对应属性可驼峰命名
    cache-enabled: true #开启全局二级缓存
    call-setters-on-nulls: true #resultMap返回的是Map时，返回值为空的键值关系
  #    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #sql语句详情打印
  global-config:
    db-config:
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)

#PageHelper分页
pagehelper:
  helperDialect: mysql
  offsetAsPageNum: true
  rowBoundsWithCount: true
  supportMethodsArguments: true
  reasonable: true
  pageSizeZero: false #pageSize=0
  params: count=countSql

swagger:
  enable: true
  title: springboot
  description: 测试系统
  version: 1.0
  name: lt
  url: http://xxx
  email: xxx@qq.com

# actuator 监控配置
management:
  #actuator端口 如果不配置做默认使用上面8080端口
  server:
    port: 8078
  endpoints:
    web:
      exposure:
        #默认值访问health,info端点  用*可以包含全部端点
        include: "*"
      #修改访问路径 2.0之前默认是/; 2.0默认是/actuator可以通过这个属性值修改
      base-path: /actuator
  endpoint:
    shutdown:
      enabled: true #打开shutdown端点
    health:
      show-details: always #获得健康检查中所有指标的详细信息

#文件路径
filePath: /home/file/

#kafka topic
kafka_topics: topic01,topic-new-1

#redis消息队列
redislist:
  mq1: mq1
  mq2: mq2
  mq3: mq3

#雪花算法
snow-flake:
  dataCenterId: 0 #数据中心
  machineId: 0 #机器标识
